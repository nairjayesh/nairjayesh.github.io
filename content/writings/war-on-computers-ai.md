---
title: The Coming War on Computers and AI
draft: true
date: 2026-02-13
---
The general public lost the war on software, when microsoft windows became the default. It's not that paying for software is bad, it's the IP that it comes with. Where you don't own the actual source code to the software service.

When you don't own the copy of software purchased, you are subjected to the whims of the corporation that produced it. Now why is that bad ? Because a corporation itself is a headless entity (or one that can easily run over by incompetent people) who's eventual motives metastasizes into self-preservation through profits over users' goodwill within the context of a growth based economy.

Growth-based economy is one where, if stonks don't go up, the whole thing goes down. Where eventually stonks and their vassal of analysts get to judge, if what the company has decided to do is good or bad for the "users". Why are these analysts the vassals ? Because when you invest in the stonks-market through various schemes such as index-funds, millions of people give the funds the voting power to determine if what the company has done is good or bad.

It wouldn't be a problem if the people who were in charge were actually compentent, and by competent, I mean being able to think through the long-term consequences of the decisions that company makes for it's products and how it impacts the users. Instead, they have blinders on, and the most important thing that matters is - to make stonks go up, which would lead to more people investing through them and them getting a bigger pay, which would lead to gratification of whatever immediate desires they do have.

The human incentives aren't all that bad, every person who works is also subjected to some form of desire to improve his standing in the world, be it a more comfortable life, or a higher status. The problem with the vassals is that, the incentives they have, seemingly lead to terrible consequences in the long-term. This is because their job doesn't actually involve anything related to value-creation. Since, their metrics don't actually track value created - and I mean real hard value that you can point to - all consequences of the decisions they make are towards no fruitful end.

This leads to a back and forth between the vassals and the owners of the company. Since owners can now "get rich" by making stonks go up and vassals get paid to pick whichever stonk is most likely to go up, they subtly manueuver each others moves to align with this. They may not always work together, but they realize that their incentives are aligned, which eventually leads to no value creation for the users.

This brings me back to AI and computers. If good quality computers become expensive to buy (a tinycomputer with NVIDIA chips now costs $60,000) due to hoarding of these computers by companies with more wealth inside datacenters, more and more people will rely on companies that interface with these datacenters (or own them in the first place). Now, think back to what happened when Windows was in charge of such a setup, but happening to your daily computing tasks. Doing simple things would be charged for, on a monthly subscription basis, where eventually the rug will be pulled from under you in order to charge even more. Web 2.0, with all it's useful services eventually stooped to this. What's worse, since you can't own the piece of software that you are paying to use, you can't even opt out of whatever the next version update is coming to make the service even more unbearable. 

AI is arguably one of the most important forms of software that we're working to create. It's not finished in the sense that other programs are, and unlike other programs it doesn't have a strictly defined requirement of the kinds of data it can operate on. So, you can get it to operate on text, images, audio, video and all other things that are part of our daily staple forms of data we consume (within the information economy). Why is this cool ? Because it can help with tasks that previously required hand-crafted rules and strictly defined logic within the space of programs to operate on different types of data, towards different goals. Where each combination of input-data and desired-goal pair could require a separate program to be written.

With AI (or more specifically Neural Nets) this is no longer the case, especially with shifts towards foundation models, more and more of the above computational pair of requirements can be fit into these models. There are even variations, where we could have tiny experts on different goals to work with different pairs of requirements within a shared space of context. What this means is that, more people can get more of their work done, and navigate the space of complexity already existing in the modern economy.

Now, if such a program is again stored and operated within a handful of data centres. This would immediately lead to restrictions on the computational requirements you can work with - from something as simple as rate-limits and metered pricing for your input-output pair to strict specifications on what input-output pair of tasks can you actually work on.

(note I need more examples here, this space needs more explanations...)

This is the coming war, absolute ownership over your computers and AI. Ability to tinker with and create more capable and cheaper computers and efficient or giant models without any usage restrictions. Of course, most people can still use these via interfaces (or API calls) to data centres. That's convenience, but there must be an option to exit and to take things into your own hands. If this doesn't happen, people will again be subjected to servitude, with levels of entshittification that perhaps we haven't yet seen. 